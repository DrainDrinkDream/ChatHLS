{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Buggy project detect, creat and batch run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buggy code detect\n",
    "Here we first detect the buggy project set for the buggy code\n",
    "\n",
    "* `reference_folder`: `./vitis_examples/02_basic_examples_vhls_fir_filter` include full, vanilla project\n",
    "\n",
    "* `buggy_folder`: `./vitis_examples_buggy/02_basic_examples_vhls_fir_filter` include buggy top modules\n",
    "\n",
    "* `output folder` `./vitis_examples_out/02_basic_examples_vhls_fir_filter/.......` include different buggy projects\n",
    "\n",
    "The initial structure of the folder should look like this:\n",
    "```tree\n",
    ".\n",
    "├── bug_run.ipynb\n",
    "├── vitis_examples\n",
    "│   └── 02_basic_examples_vhls_fir_filter\n",
    "├── vitis_examples_buggy\n",
    "│   └── 02_basic_examples_vhls_fir_filter\n",
    "└── vitis_examples_out\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "parser_script_path = './parser_single.py' # parser script\n",
    "O_PATH = \"./NL2CPP_gpt_4o_simple\"  # Replace with the desired output folder\n",
    "S_PATH = \"./origin_projects\"  # Replace with the actual path to the reference folder\n",
    "B_PATH = \"./origin_projects\"  # Replace with the actual path to the buggy folder\n",
    "THREAD =   6\n",
    "TCL_SCRIPT = \"run_hls.tcl\"\n",
    "R_MODULE_NAMES = [\n",
    "    \"2mm\",\n",
    "    \"3mm\",\n",
    "    \"atax\",\n",
    "    \"bicg\",\n",
    "    \"correlation\",\n",
    "    \"covariance\",\n",
    "    \"floyd-warshall\",\n",
    "    \"gemm\",\n",
    "    \"gesummv\",\n",
    "    \"heat-3d\",\n",
    "    \"jacobi-2d\",\n",
    "    \"mvt\",\n",
    "    \"nussinov\",\n",
    "    \"symm\",\n",
    "    \"syr2k\",\n",
    "    \"trmm\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "def detect_buggy_projects(buggy_folder, reference_top_module_names):\n",
    "    buggy_projects = {}\n",
    "    \n",
    "    # List of acceptable source file extensions\n",
    "    acceptable_extensions = ['.c', '.cc', '.cpp', '.h', '.hpp']  # Add more extensions as needed\n",
    "    \n",
    "    # Iterate through the directories in the buggy folder\n",
    "    for dirpath, dirnames, filenames in os.walk(buggy_folder):\n",
    "        # Only check in subdirectories\n",
    "        if dirpath != buggy_folder:\n",
    "            buggy_files = []\n",
    "            ref_names = []\n",
    "            \n",
    "            # Check for buggy files based on their naming conventions\n",
    "            for filename in filenames:\n",
    "                # Check if the filename ends with any of the acceptable extensions\n",
    "                if any(filename.endswith(ext) for ext in acceptable_extensions):\n",
    "                    # Extract the base name without the extension\n",
    "                    base_name = os.path.splitext(filename)[0]\n",
    "                    \n",
    "                    # Check if the filename contains any of the reference top module names\n",
    "                    for ref_name in reference_top_module_names:\n",
    "                        if base_name.startswith(\"modified_\"):\n",
    "                            base_name = base_name[len(\"modified_\"):]\n",
    "                        if base_name.startswith(ref_name):  # Check if the base name starts with the ref_name\n",
    "                            buggy_files.append(filename)\n",
    "                            ref_names.append(ref_name)\n",
    "                            break  # Stop after finding a match\n",
    "\n",
    "            if buggy_files:\n",
    "                project_name = os.path.basename(dirpath)  # Use the directory name as the project key\n",
    "                buggy_projects[project_name] = {\n",
    "                    'replaced_file': ref_names,  # Store the reference top module name\n",
    "                    'files': buggy_files,\n",
    "                    'path': dirpath  # Store the path to the directory\n",
    "                }\n",
    "\n",
    "    return buggy_projects\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "def assemble_buggy_projects(buggy_projects, reference_folder, output_folder, reference_top_module_names):\n",
    "    if not buggy_projects:\n",
    "        print(\"no buggy_projects\")\n",
    "        return\n",
    "\n",
    "    for project, info in buggy_projects.items():\n",
    "        buggy_files = info['files']\n",
    "        dirpath = info['path']  # Get the directory path for the buggy files\n",
    "        \n",
    "        # Create a collection folder in output\n",
    "        collection_folder = os.path.join(output_folder, project)\n",
    "        os.makedirs(collection_folder, exist_ok=True)\n",
    "\n",
    "        for buggy_file in buggy_files:\n",
    "            # Determine the bug type from the buggy file name using the reference top module names\n",
    "            bug_type = None  # Initialize bug_type as None\n",
    "            for ref_name in reference_top_module_names:\n",
    "                if buggy_file.startswith(ref_name):  # Check if buggy_file starts with the ref_name\n",
    "                    # Extract the bug type correctly by removing the reference name\n",
    "                    remainder = buggy_file[len(ref_name):].lstrip('_')  # Remove leading underscore if it exists\n",
    "                    bug_type = remainder.split('.')[0]  # Extract bug type safely\n",
    "                    break  # Stop after finding a match\n",
    "            \n",
    "            if bug_type is None:\n",
    "                continue\n",
    "            \n",
    "            # Create a new subfolder for the bug type (buggy project folder)\n",
    "            buggy_project_folder = os.path.join(collection_folder)\n",
    "            # add an extra layer to indicate reference top module\n",
    "\n",
    "            os.makedirs(buggy_project_folder, exist_ok=True)\n",
    "\n",
    "            # Find the original reference project folder based on the buggy project name\n",
    "            reference_project_folder = os.path.join(reference_folder, project)  # Assuming the original project is named similarly\n",
    "\n",
    "            if not os.path.exists(reference_project_folder):\n",
    "                continue\n",
    "\n",
    "            # Copy all files from the original reference project\n",
    "            for item in os.listdir(reference_project_folder):\n",
    "                source_item = os.path.join(reference_project_folder, item)\n",
    "                if os.path.isfile(source_item):\n",
    "                    if(buggy_file == f\"{ref_name}.cpp\"):\n",
    "                        shutil.copytree(reference_project_folder, buggy_project_folder, dirs_exist_ok=True)\n",
    "            \n",
    "\n",
    "            buggy_file_path = os.path.join(dirpath, buggy_file)  # Use the stored dirpath\n",
    "            new_file_path = os.path.join(buggy_project_folder, buggy_file)\n",
    "            print(\"buggy_file_path\", buggy_file_path)\n",
    "            print(\"new_file_path\", new_file_path)\n",
    "            # Replace the top module file with the buggy file\n",
    "            shutil.copy(buggy_file_path, new_file_path)\n",
    "\n",
    "            #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "buggy_folder = B_PATH  # Replace with the actual path to the buggy folder\n",
    "reference_folder = S_PATH  # Replace with the actual path to the reference folder\n",
    "output_folder = O_PATH  # Replace with the desired output folder\n",
    "\n",
    "reference_top_module_names = R_MODULE_NAMES  # Add more top module names as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect buggy projects\n",
    "buggy_projects = detect_buggy_projects(buggy_folder, reference_top_module_names)\n",
    "print(buggy_projects)\n",
    "\n",
    "# Check if there are any buggy projects detected\n",
    "\n",
    "# Assemble the buggy projects\n",
    "assemble_buggy_projects(buggy_projects, reference_folder, output_folder, reference_top_module_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "import concurrent.futures\n",
    "import time\n",
    "import threading\n",
    "import psutil\n",
    "from colorama import Fore, Style\n",
    "\n",
    "# Shared structure to hold task status\n",
    "task_status = {}\n",
    "task_completed = threading.Event()  # Event to signal when all tasks are completed\n",
    "final_results = {\n",
    "    'DONE': [],\n",
    "    'DONE_ERROR': [],\n",
    "    'HANG_ERROR': []\n",
    "}\n",
    "\n",
    "def modify_tcl_script(tcl_script_path):\n",
    "    \"\"\"Modify the TCL script to change hls_exec value.\"\"\"\n",
    "    with open(tcl_script_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    # Modify the specific line\n",
    "    for i, line in enumerate(lines):\n",
    "        if \"set hls_exec 0\" in line:\n",
    "            lines[i] = line.replace(\"set hls_exec 0\", \"set hls_exec 2\")\n",
    "            print(f\"Modified {tcl_script_path}: set hls_exec changed to 2\")\n",
    "            break\n",
    "\n",
    "    # Write the modified content back to the file\n",
    "    with open(tcl_script_path, 'w') as file:\n",
    "        file.writelines(lines)\n",
    "\n",
    "def kill_csim_process():\n",
    "    \"\"\"Kill the csim.exe process if it exists.\"\"\"\n",
    "    for proc in psutil.process_iter():\n",
    "        try:\n",
    "            if proc.name() == \"csim.exe\":\n",
    "                proc.kill()\n",
    "                print(f\"{Fore.RED}Killed csim.exe process.{Style.RESET_ALL}\")\n",
    "        except (psutil.NoSuchProcess, psutil.AccessDenied):\n",
    "            continue\n",
    "\n",
    "def update_task_status(project, elapsed_time, status):\n",
    "    \"\"\"Update the shared task status.\"\"\"\n",
    "    task_status[(project)] = (elapsed_time, status)\n",
    "\n",
    "def run_vitis_hls_for_project(project_info):\n",
    "    project, buggy_project_folder, logs_folder = project_info\n",
    "    start_time = time.time()  # Start the timer\n",
    "    dataset_tcl_script =  TCL_SCRIPT  # Set just the script name\n",
    "    status = \"RUNNING\"\n",
    "\n",
    "    if os.path.exists(os.path.join(buggy_project_folder, dataset_tcl_script)):\n",
    "        print(f\"{Fore.GREEN}Running Vitis HLS for project: {project}, TCL script: {dataset_tcl_script}{Style.RESET_ALL}\")\n",
    "\n",
    "        # Redirect stdout and stderr to a log file\n",
    "        log_file_path = os.path.join(logs_folder, f\"{project}_log.txt\")\n",
    "        with open(log_file_path, 'w') as log_file:\n",
    "            try:\n",
    "                # Run the Vitis HLS command by changing directory with a timeout\n",
    "                process = subprocess.Popen([\"./vitis_hls.bat\", dataset_tcl_script], stdout=log_file, stderr=subprocess.STDOUT, cwd=buggy_project_folder)\n",
    "                \n",
    "                while True:\n",
    "                    elapsed_time = time.time() - start_time\n",
    "                    update_task_status(project, elapsed_time, status)\n",
    "\n",
    "                    if process.poll() is not None:  # Process has finished\n",
    "                        if process.returncode == 0:  # Successful run\n",
    "                            status = \"DONE\"\n",
    "                        else:  # Error during execution\n",
    "                            status = \"DONE ERROR\"\n",
    "                        update_task_status(project, elapsed_time, status)\n",
    "                        final_results[status].append((project, elapsed_time))  # Record results\n",
    "                        break\n",
    "                    if elapsed_time > 300:  # 5 minutes timeout\n",
    "                        print(f\"{Fore.YELLOW}Timeout: Vitis HLS for {project} is hanging. Killing csim.exe and skipping this iteration.{Style.RESET_ALL}\")\n",
    "                        kill_csim_process()  # Kill csim.exe process\n",
    "                        process.terminate()  # Terminate the Vitis HLS process\n",
    "                        status = \"HANG_ERROR\"\n",
    "                        update_task_status(project, elapsed_time, status)\n",
    "                        final_results[status].append((project, elapsed_time))  # Record results\n",
    "                        break\n",
    "                    time.sleep(20)  # Refresh every 2 seconds\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error running Vitis HLS for {project}. Error: {e}\")\n",
    "                status = \"DONE ERROR\"\n",
    "                update_task_status(project, elapsed_time, status)\n",
    "                final_results[status].append((project, elapsed_time))  # Record results\n",
    "    else:\n",
    "        print(f\"Warning: {dataset_tcl_script} not found in {buggy_project_folder}. Skipping compilation.\")\n",
    "        status = \"DONE ERROR\"\n",
    "        update_task_status(project, elapsed_time, status)\n",
    "        final_results[status].append((project, elapsed_time))  # Record results\n",
    "\n",
    "\n",
    "def print_final_results(task_status):\n",
    "    \"\"\"Log the final results of the tasks.\"\"\"\n",
    "    done_count = 0\n",
    "    done_error_count = 0\n",
    "    hang_error_count = 0\n",
    "    \n",
    "    with open(\"run_results.log\", \"w\") as log_file:\n",
    "        log_file.write(\"===========================================\\n\")\n",
    "        for (project), (elapsed_time, status) in task_status.items():\n",
    "            if status == \"DONE\":\n",
    "                log_file.write(f\"@DONE      :  {project} , Executed time: {elapsed_time:.2f} seconds\\n\")\n",
    "                done_count += 1\n",
    "            elif status == \"DONE ERROR\":\n",
    "                log_file.write(f\"@DONE_ERROR: {project} , Executed time: {elapsed_time:.2f} seconds\\n\")\n",
    "                done_error_count += 1\n",
    "            elif status == \"HANG_ERROR\":\n",
    "                log_file.write(f\"@HANG_ERROR: {project} , Executed time: {elapsed_time:.2f} seconds\\n\")\n",
    "                hang_error_count += 1\n",
    "        \n",
    "        log_file.write(\"===========================================\\n\")\n",
    "        log_file.write(f\"Total tasks: {done_count + done_error_count + hang_error_count}\\n\")\n",
    "        log_file.write(f\"@DONE tasks total: {done_count}\\n\")\n",
    "        log_file.write(f\"@DONE_ERROR tasks total: {done_error_count}\\n\")\n",
    "        log_file.write(f\"@HANG_ERROR tasks total: {hang_error_count}\\n\")\n",
    "        log_file.write(\"===========================================\\n\")\n",
    "\n",
    "\n",
    "\n",
    "def clear_output():\n",
    "    \"\"\"Clear the console output.\"\"\"\n",
    "    os.system('cls' if os.name == 'nt' else 'clear')\n",
    "\n",
    "def print_all_task_statuses():\n",
    "    \"\"\"Print the status of all tasks.\"\"\"\n",
    "    while not task_completed.is_set():  # Continue until all tasks are completed\n",
    "        if not task_status:\n",
    "            continue\n",
    "        \n",
    "        # Clear the previous output\n",
    "        clear_output()\n",
    "        \n",
    "        print(\"\\nCurrent Task status:\")\n",
    "        \n",
    "        # Make a copy of the task_status dictionary for safe iteration\n",
    "        current_statuses = task_status.copy()\n",
    "        \n",
    "        done_count = 0\n",
    "        done_error_count = 0\n",
    "        hang_error_count = 0\n",
    "        \n",
    "        for (project), (elapsed_time, status) in current_statuses.items():\n",
    "            if status == \"DONE\":\n",
    "                done_count += 1\n",
    "                print(f\"Task for {Fore.BLUE}{project}{Style.RESET_ALL} Executed time: {elapsed_time:.2f} seconds - {Fore.GREEN}DONE{Style.RESET_ALL}\")\n",
    "            elif status == \"DONE ERROR\":\n",
    "                done_error_count += 1\n",
    "                print(f\"Task for {Fore.BLUE}{project}{Style.RESET_ALL}  Executed time: {elapsed_time:.2f} seconds - {Fore.YELLOW}DONE ERROR{Style.RESET_ALL}\")\n",
    "            elif status == \"HANG_ERROR\":\n",
    "                hang_error_count += 1\n",
    "                print(f\"Task for {Fore.BLUE}{project}{Style.RESET_ALL}  Executed time: {elapsed_time:.2f} seconds - {Fore.RED}HANG_ERROR{Style.RESET_ALL}\")\n",
    "            else:\n",
    "                print(f\"Task for {Fore.BLUE}{project}{Style.RESET_ALL}  Executed time: {elapsed_time:.2f} seconds - {Fore.WHITE}{status}{Style.RESET_ALL}\")\n",
    "        \n",
    "        print(\"-\" * 60)  # Separator for clarity\n",
    "        print(f\"Total tasks: {done_count + done_error_count + hang_error_count}\")\n",
    "        print(f\"@DONE tasks total: {done_count}\")\n",
    "        print(f\"@DONE_ERROR tasks total: {done_error_count}\")\n",
    "        print(f\"@HANG_ERROR tasks total: {hang_error_count}\")\n",
    "        print(\"=\" * 60)  # Separator for clarity\n",
    "        \n",
    "        time.sleep(20)  # Refresh every 2 seconds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import threading\n",
    "import concurrent.futures\n",
    "\n",
    "\n",
    "def run_vitis_hls(buggy_projects, output_folder):\n",
    "    if not buggy_projects:\n",
    "        print(\"No buggy projects to compile.\")\n",
    "        return\n",
    "\n",
    "    project_infos = []\n",
    "\n",
    "    for project, info in buggy_projects.items():\n",
    "        project_path = os.path.join(output_folder, project)\n",
    "\n",
    "        ref_path = os.path.join(project_path)\n",
    "        logs_folder = os.path.join(ref_path, \"logs\")\n",
    "        os.makedirs(logs_folder, exist_ok=True)\n",
    "\n",
    "        buggy_project_folder = os.path.join(ref_path)\n",
    "        project_infos.append((f\"{project}\", buggy_project_folder, logs_folder))\n",
    "\n",
    "    # Run task status printer in a separate thread\n",
    "    status_thread = threading.Thread(target=print_all_task_statuses, daemon=True)\n",
    "    status_thread.start()\n",
    "\n",
    "    # Run Vitis HLS in parallel\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=THREAD) as executor:\n",
    "        futures = [executor.submit(run_vitis_hls_for_project, project_info) for project_info in project_infos]\n",
    "        concurrent.futures.wait(futures)  # Wait for all tasks to complete\n",
    "\n",
    "    # Assuming `task_completed` is a threading.Event() instance declared elsewhere\n",
    "    task_completed.set()  # Signal that all tasks are completed\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "# Assuming `buggy_projects` is already populated from the previous step\n",
    "run_vitis_hls(buggy_projects, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_final_results(task_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def get_file_size_mb(file_path):\n",
    "    return os.path.getsize(file_path) / (1024 * 1024)  # Convert bytes to MB\n",
    "\n",
    "\n",
    "def copy_log_files(O_PATH):\n",
    "    input_folder = O_PATH\n",
    "    output_folder = f\"logs_{os.path.basename(O_PATH)}\"\n",
    "\n",
    "    # Check if the input folder exists\n",
    "    if not os.path.isdir(input_folder):\n",
    "        print(\"Error: Input folder does not exist.\")\n",
    "        return None\n",
    "\n",
    "    # Check if the output folder exists, if not, create it\n",
    "    if not os.path.isdir(output_folder):\n",
    "        print(\"Output folder does not exist. Creating it now...\")\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Find all files ending with '_log.txt' in the input folder and subfolders\n",
    "    # and copy them to the output folder\n",
    "    #for file in glob.glob(os.path.join(input_folder, '**', '*_log.txt'), recursive=True):\n",
    "    #    shutil.copy(file, output_folder)\n",
    "    for file in glob.glob(os.path.join(input_folder, '**', '*_log.txt'), recursive=True):\n",
    "        file_size_mb = get_file_size_mb(file)\n",
    "        if file_size_mb <= 100:  # Only copy if file size is 100MB or less\n",
    "            shutil.copy(file, output_folder)\n",
    "        else:\n",
    "            print(f\"Skipped {file} as its size ({file_size_mb:.2f} MB) exceeds 100 MB\")\n",
    "\n",
    "    print(\"All files have been copied successfully.\")\n",
    "    return output_folder\n",
    "\n",
    "\n",
    "def run_parser(parser_path, input_folder, json=True, csv=True):\n",
    "    # Generate output file names\n",
    "    base_name = f\"result_{os.path.basename(input_folder)}\"\n",
    "    csv_path = f\"{base_name}.csv\" if csv else None\n",
    "    json_path = f\"{base_name}.json\" if json else None\n",
    "\n",
    "    command = [sys.executable, parser_path]\n",
    "    \n",
    "    if csv and csv_path:\n",
    "        command.extend(['-c', csv_path])\n",
    "    if json and json_path:\n",
    "        command.extend(['-j', json_path])\n",
    "    \n",
    "    command.append(input_folder)\n",
    "    \n",
    "    result = subprocess.run(command, capture_output=True, text=True)\n",
    "    \n",
    "    print(\"STDOUT:\")\n",
    "    print(result.stdout)\n",
    "    \n",
    "    print(\"STDERR:\")\n",
    "    print(result.stderr)\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, copy the log files\n",
    "output_folder = copy_log_files(O_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if output_folder:\n",
    "    # Now run the parser on the copied log files\n",
    "    result = run_parser(parser_script_path, output_folder, json=False, csv=True)\n",
    "\n",
    "    # Print the generated file names\n",
    "    print(f\"CSV output: result_{os.path.basename(output_folder)}.csv\")\n",
    "    result = run_parser(parser_script_path, output_folder, json=True, csv=False)\n",
    "    print(f\"JSON output: result_{os.path.basename(output_folder)}.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Reality",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
